"""
Prepare model for Hugging Face release.

Creates a release directory with all necessary files for HF Hub upload.

Usage:
    python prepare_release.py --output ./release
"""

import argparse
import shutil
from pathlib import Path
import json
import numpy as np
import yaml

try:
    from safetensors.numpy import save_file as save_safetensors
    HAS_SAFETENSORS = True
except ImportError:
    HAS_SAFETENSORS = False
    print("Note: safetensors not installed, skipping .safetensors export")
    print("Install with: pip install safetensors")


def load_config():
    config_path = Path(__file__).parent / "config.yaml"
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)


def create_model_card(output_dir: Path, config: dict, metrics: dict):
    """Create README.md model card for Hugging Face."""
    
    model_card = f'''---
license: mit
tags:
- audio
- music
- ai-detection
- onnx
- logistic-regression
pipeline_tag: audio-classification
---

# AI Music Detector

Detects music generated by Suno <= 5 and Udio <= 1.5 using spectral fakeprint analysis.

## Model Description

This model analyzes the frequency spectrum of audio to detect characteristic artifacts 
left by neural vocoders in AI music generators. These "fakeprints" are regularly-spaced 
peaks in the spectrum caused by transposed convolution (deconvolution) layers.

### Architecture

- **Type**: Logistic Regression on spectral features
- **Input**: Fakeprint vector ({config.get('output_bins', 3585)} features)
- **Output**: Probability of AI-generated content (0.0 = Real, 1.0 = AI)

### Preprocessing

Audio must be preprocessed to extract fakeprints:

| Parameter | Value |
|-----------|-------|
| Sample Rate | {config.get('sample_rate', 16000)} Hz |
| FFT Size | {config.get('n_fft', 8192)} |
| Frequency Range | {config.get('freq_min', 1000)}-{config.get('freq_max', 8000)} Hz |
| Hull Area | {config.get('hull_area', 10)} bins |

## Performance

Evaluated on a held-out test set of {metrics.get('n_test', 17866):,} samples ({metrics.get('n_test_real', 5741):,} real, {metrics.get('n_test_fake', 12125):,} AI-generated).

| Metric | Value |
|--------|-------|
| Accuracy | {metrics.get('accuracy', 0.999):.2%} |
| Precision | {metrics.get('precision', 0.999):.4f} |
| Recall | {metrics.get('recall', 0.999):.4f} |
| F1 Score | {metrics.get('f1', 0.999):.4f} |
| False Positive Rate | {metrics.get('fpr', 0.003):.2%} |
| False Negative Rate | {metrics.get('fnr', 0.001):.2%} |

## Training Data

- **Real Music**: FMA Medium (25k), Proprietary (5k)
- **AI-Generated**: SONICS dataset (49k), Proprietary (10k)

## Usage

### Python (ONNX)

```python
import numpy as np
import onnxruntime as ort

# Load model
session = ort.InferenceSession("ai_music_detector.onnx")

# fakeprint = extract_fakeprint(audio_file)  # Your preprocessing
output = session.run(None, {{"fakeprint": fakeprint.reshape(1, -1)}})
ai_probability = output[0][0, 0]

print(f"AI Probability: {{ai_probability:.1%}}")
```

### Python (Safetensors)

```python
from safetensors.numpy import load_file
import numpy as np

weights = load_file("model.safetensors")
w = weights["weights"]  # Shape: (1, 3585)
b = weights["bias"]     # Shape: (1,)

# fakeprint = extract_fakeprint(audio_file)
logit = np.dot(fakeprint, w.T) + b
probability = 1 / (1 + np.exp(-logit))
```

## Limitations

- **Sample Rate Dependent**: Audio must be resampled to {config.get('sample_rate', 16000)} Hz
- **Minimum Duration**: Works best with 10+ seconds of audio
- **Evolving Generators**: Needs retraining on new generations of AI music generators

## Acknowledgements

This implementation is based on the fakeprint detection method proposed by Afchar et al. [1], 
which demonstrates that neural vocoders in generative music models produce characteristic 
frequency-domain artifacts due to their deconvolution architecture.

### References

[1] D. Afchar, G. Meseguer-Brocal, K. Akesbi, and R. Hennequin, "A Fourier Explanation of 
AI-music Artifacts," in *Proc. International Society for Music Information Retrieval 
Conference (ISMIR)*, 2025. Available: https://arxiv.org/abs/2506.19108

## License

MIT License
'''
    
    readme_path = output_dir / "README.md"
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(model_card)
    print(f"Created: {readme_path}")


def create_config_json(output_dir: Path, config: dict):
    """Create config.json for HF."""
    
    hf_config = {
        "model_type": "logistic_regression",
        "task": "audio-classification",
        "labels": ["real", "ai_generated"],
        "preprocessing": {
            "sample_rate": config.get("sample_rate", 16000),
            "n_fft": config.get("n_fft", 8192),
            "freq_min": config.get("freq_min", 1000),
            "freq_max": config.get("freq_max", 8000),
            "hull_area": config.get("hull_area", 10),
            "max_db": config.get("max_db", 5),
            "min_db": config.get("min_db", -45)
        },
        "input_features": config.get("output_bins", 3585),
        "threshold": 0.5
    }
    
    config_path = output_dir / "config.json"
    with open(config_path, 'w') as f:
        json.dump(hf_config, f, indent=2)
    print(f"Created: {config_path}")


def main():
    parser = argparse.ArgumentParser(description="Prepare model for HuggingFace release")
    parser.add_argument("--output", type=str, default="./release", help="Output directory")
    parser.add_argument("--model-dir", type=str, default=None, help="Model directory")
    args = parser.parse_args()
    
    # Load config
    config = load_config()
    model_dir = Path(args.model_dir) if args.model_dir else Path(config["paths"]["model_dir"])
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print(f"Preparing release in: {output_dir}")
    print(f"Source model: {model_dir}")
    
    # Load weights
    weights_path = model_dir / "weights.npz"
    data = np.load(weights_path)
    weights = data["weights"]
    bias = data["bias"]
    
    print(f"Weights shape: {weights.shape}")
    print(f"Bias: {bias}")
    
    # Load metrics if available
    model_config_path = model_dir / "model_config.yaml"
    if model_config_path.exists():
        with open(model_config_path, 'r') as f:
            model_config = yaml.safe_load(f)
        metrics = model_config.get("training_metrics", {})
        feature_config = model_config.get("feature_config", {})
    else:
        metrics = {}
        feature_config = {}
    
    # Merge configs
    full_config = {
        **config.get("audio", {}),
        **config.get("fakeprint", {}),
        **feature_config
    }
    
    # 1. Copy ONNX model
    onnx_src = model_dir / "ai_music_detector.onnx"
    if onnx_src.exists():
        shutil.copy(onnx_src, output_dir / "ai_music_detector.onnx")
        print(f"Copied: ai_music_detector.onnx")
    else:
        print(f"Warning: ONNX model not found at {onnx_src}")
    
    # 2. Create safetensors
    if HAS_SAFETENSORS:
        tensors = {
            "weights": weights.astype(np.float32),
            "bias": bias.astype(np.float32)
        }
        safetensors_path = output_dir / "model.safetensors"
        save_safetensors(tensors, str(safetensors_path))
        print(f"Created: {safetensors_path}")
    
    # 3. Copy numpy weights
    shutil.copy(weights_path, output_dir / "weights.npz")
    print(f"Copied: weights.npz")
    
    # 4. Create model card
    create_model_card(output_dir, full_config, metrics)
    
    # 5. Create config.json
    create_config_json(output_dir, full_config)
    
    # 6. Copy preprocessing config
    preprocessing_config = {
        "sample_rate": full_config.get("sample_rate", 16000),
        "n_fft": full_config.get("n_fft", 8192),
        "freq_min": full_config.get("freq_min", 1000),
        "freq_max": full_config.get("freq_max", 8000),
        "hull_area": full_config.get("hull_area", 10),
        "max_db": full_config.get("max_db", 5),
        "min_db": full_config.get("min_db", -45)
    }
    
    preprocess_path = output_dir / "preprocessing_config.json"
    with open(preprocess_path, 'w') as f:
        json.dump(preprocessing_config, f, indent=2)
    print(f"Created: {preprocess_path}")
    
    print("\n" + "="*60)
    print("Release package ready!")
    print("="*60)
    print(f"\nFiles in {output_dir}:")
    for f in sorted(output_dir.iterdir()):
        size = f.stat().st_size
        if size > 1024:
            print(f"  {f.name} ({size/1024:.1f} KB)")
        else:
            print(f"  {f.name} ({size} bytes)")
    
    print("\nTo upload to HuggingFace:")
    print("  hf auth login")
    print("  hf repo create ai-music-detector --type model")
    print(f"  hf upload YOUR_USERNAME/ai-music-detector {output_dir} --repo-type model")


if __name__ == "__main__":
    main()
